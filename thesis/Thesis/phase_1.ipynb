{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(split_part):\n",
    "    og_data = np.load('og_data.npy')\n",
    "    labels = np.load('labels.npy')\n",
    "    \n",
    "    # Label encoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    labels = le.transform(labels)\n",
    "    x_train, x_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "    smin = -1\n",
    "    smax = 1\n",
    "    x = og_data\n",
    "    xmax, xmin = x.max(), x.min()\n",
    "    norm_data = (x - xmin)*(smax - smin)/(xmax - xmin) + smin\n",
    "\n",
    "    # Sorting the data\n",
    "    sorted_index = np.argsort(labels)\n",
    "    sorted_labels = labels[sorted_index]\n",
    "    sorted_og_data = og_data[sorted_index]\n",
    "    sorted_norm_data = norm_data[sorted_index]\n",
    "\n",
    "    # split the data into train and test\n",
    "    test_random_indices = []\n",
    "    for i in range(sorted_labels.shape[0]/split_part):\n",
    "        index = i*split_part + randint(0, split_part - 1)\n",
    "        test_random_indices.append(index)\n",
    "\n",
    "    x_train = np.delete(sorted_norm_data, test_random_indices, 0)\n",
    "    x_test = sorted_norm_data[test_random_indices]\n",
    "    y_train = np.delete(sorted_labels, test_random_indices)\n",
    "    y_test = sorted_labels[test_random_indices]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (300, 21764))\n",
      "(300, 'train samples')\n",
      "(60, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(6)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration started -->  completed\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results_top = []\n",
    "for i in range(1):\n",
    "    print '{0} iteration started --> '.format(i),\n",
    "    clf = LinearSVC()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(6)\n",
    "    clf.fit(x_train, y_train)\n",
    "    results.append(clf.score(x_test, y_test))\n",
    "    \n",
    "    top_r = []\n",
    "    for j in [1, 3, 5, 10]:\n",
    "        predicted_correct = 0\n",
    "        for k in range(60):\n",
    "            predicted_lbl = clf.predict(x_test[k].reshape(1, -1))\n",
    "            decision_lbl = clf.decision_function(x_test[k].reshape(1, -1))[0]\n",
    "\n",
    "            top_class = j\n",
    "            top_n = np.argsort(decision_lbl)[::-1][:top_class]\n",
    "\n",
    "            if y_test[k] in top_n:\n",
    "                predicted_correct += 1.0/60\n",
    "        top_r.append(predicted_correct)\n",
    "    results_top.append(top_r)\n",
    "    print 'completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With normalisation to data\n",
      "LinearSVC result for Top_1 is 0.16666666666666666.\n",
      "LinearSVC result for Top_3 is 0.36666666666666664.\n",
      "LinearSVC result for Top_5 is 0.5833333333333335.\n",
      "LinearSVC result for Top_10 is 0.7166666666666672.\n"
     ]
    }
   ],
   "source": [
    "results_t = np.array(results_top)\n",
    "\n",
    "results_t = np.average(results_t, axis=0)\n",
    "\n",
    "Matrics = ['Top_1', 'Top_3', 'Top_5', 'Top_10']\n",
    "\n",
    "LinearSVC_results = zip(Matrics, results_t)\n",
    "\n",
    "print \"With normalisation to data\"\n",
    "for i in LinearSVC_results:\n",
    "    print 'LinearSVC result for %s is %s.' % (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_correct = 0\n",
    "for i in range(60):\n",
    "    predicted_lbl = clf.predict(x_test[i].reshape(1, -1))\n",
    "    decision_lbl = clf.decision_function(x_test[i].reshape(1, -1))[0]\n",
    "\n",
    "    top_class = 3\n",
    "    top_n = np.argsort(decision_lbl)[::-1][:top_class]\n",
    "    \n",
    "    if y_test[i] in top_n:\n",
    "        predicted_correct += 1.0/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25,\n",
       " 0.2833333333333333,\n",
       " 0.26666666666666666,\n",
       " 0.31666666666666665,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.2833333333333333,\n",
       " 0.15,\n",
       " 0.21666666666666667,\n",
       " 0.16666666666666666,\n",
       " 0.21666666666666667,\n",
       " 0.2,\n",
       " 0.21666666666666667,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.13333333333333333,\n",
       " 0.26666666666666666,\n",
       " 0.18333333333333332,\n",
       " 0.2,\n",
       " 0.23333333333333334,\n",
       " 0.21666666666666667,\n",
       " 0.21666666666666667,\n",
       " 0.26666666666666666,\n",
       " 0.21666666666666667,\n",
       " 0.2,\n",
       " 0.2833333333333333,\n",
       " 0.2,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.23333333333333334,\n",
       " 0.26666666666666666,\n",
       " 0.2833333333333333,\n",
       " 0.21666666666666667,\n",
       " 0.25,\n",
       " 0.3333333333333333,\n",
       " 0.23333333333333334,\n",
       " 0.15,\n",
       " 0.21666666666666667,\n",
       " 0.2833333333333333,\n",
       " 0.31666666666666665,\n",
       " 0.23333333333333334,\n",
       " 0.21666666666666667,\n",
       " 0.25,\n",
       " 0.23333333333333334,\n",
       " 0.2,\n",
       " 0.31666666666666665,\n",
       " 0.21666666666666667,\n",
       " 0.31666666666666665,\n",
       " 0.21666666666666667,\n",
       " 0.21666666666666667]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('train', 0.026734342151736153)] train ['coat']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "lbs = clf.classes_\n",
    "for i in range(60):\n",
    "    pb = clf.predict(x_test[0].reshape(1, -1))\n",
    "    probs = clf.predict_proba(x_test[i].reshape(1, -1))\n",
    "    best_n = np.argsort(probs, axis=1)[0][::-1]\n",
    "    best_n = best_n[:30]\n",
    "    predicted_lbs = list()\n",
    "    lbl_probs = list()\n",
    "    for j in range(1):\n",
    "        predicted_lbs.append(lbs[best_n[j]])\n",
    "        lbl_probs.append(probs[0][best_n[j]])\n",
    "    predictions = zip(predicted_lbs, lbl_probs)\n",
    "    \n",
    "    if y_test[i] in predicted_lbs:\n",
    "        print predictions, y_test[i], pb\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
